# A Scalable Real-Time Data Assimilation Framework for Predicting Turbulent Atmosphere Dynamics
This repository contains the scalable implementation of our generic real-time data assimilation (DA) framwork for estimating turbulent dynamics, consisting of ensemble score filter (EnSF), vision Transformer (ViT) surrogate, and coupled experiments.    
<img src="./workflow.png" width="500">

## Contributions
- A generic real-time data assimilation (DA) framework for estimating turbulent dynamics, providing significantly more accurate predictions than the state-of-the-art LETKF method.
- Strong and weak scaling capabilities of our proposed DA framework on the Frontier supercomputer.
- Large-scale ViT training up to 2.5B parameters on Frontier.

## EnSF scaling 
We show the scaling of EnSF with a high-dimensional Lorenz-96 system with up to 100M variables. The data is generated by 
```bash
python ensf/problem_gen.py
```
and the EnSF calculation follows 
```bash
python ensf/run_ensf.py 
```
A [job script](./ensf/job.sb) is provided for the scaling study on Frontier. 

## ViT scaling 
We show the scaling of ViT surrogate for [surface quasi-geostrophic (SQG)](https://github.com/jswhit/sqgturb) in following steps. 

### Data generation
We generate the SQG data using this [repo](https://github.com/jswhit/sqgturb).

### Data preprocesssing
We pre-process the SQG data as follows,
```bash
CMD="python ./src/data_preprocessing/sqg_256_split_mpi.py"
srun --nodes=${SLURM_NNODES} \
               --ntasks=$((SLURM_NNODES*8)) \
               --ntasks-per-node=8 \
               --gpu-bind=closest \
               -c7 \
               $CMD
CMD="python ./src/data_preprocessing/nc2np_equally_sqg_256_mpi.py \
--root_dir /mnt/bb/junqi/splited_2hr_per_file \
--save_dir /mnt/bb/junqi/sqg_256_npy_2hr_per_file \
--start_train_day 100 \
--start_val_day 2299 \
--start_test_day 2574  \
--end_day 2843 \
--num_shards 1
"
srun --nodes=${SLURM_NNODES} \
               --ntasks=$((SLURM_NNODES*8)) \
               --ntasks-per-node=8 \
               --gpu-bind=closest \
               -c7 \
               $CMD
```
### Distributed training 
A [job script](./scripts/job.sh) is provided for scaling study on Frontier. The `DIST` backend can be changed to `ddp`, `deepspeed`, and `fsdp`. For DeepSpeed, tuning knobs are exposed via the [configuration file](./configs/ds_config.yaml), e.g., 
```bash
    "allgather_partitions": true,
    "allgather_bucket_size": 500000000,
    "overlap_comm": true,
    "reduce_scatter": false,
    "reduce_bucket_size": 500000000,
    "contiguous_gradients": true
```
For FSDP, the sharding strategies can be changed to `FULL_SHARD`, `SHARD_GRAD_OP`, or `HYBRID_SHARD`. 

The model architecturs for each input sizes (64x64, 128x128, 256x256) are defined in [configs](./configs). 

## Coupled experiments
We incorporated the EnSF method with a trained ViT model for coupled auto-regressive prediction tests on 64x64 image size. Two sets of experiment scripts are provided for:
1. Pure ViT auto-regressive predictions without EnSF coupled, Note we still use EnSF ensembles to initialize the 'step zero' ONLY for a fair comparison. You can check this [job script](./coupled_vit_ensf/run_vit.sh).
2. Coupled ViT-EnSF auto-regressive prediction tests. EnSF calibrates and updates the initial conditions of the ViT predictions at the current step using observations to improve the ViT predictions for the next step. Note we have the option in the running script to add additional 'jump noises'. You can check this [job script](./coupled_vit_ensf/run_coupled_ensf_vit.sh).

## Results
The plots of the results are generated using this [script](./plot.ipynb), and the corresponding raw job logs can be [downloaded](https://www.dropbox.com/scl/fo/yq9q60k8sjb2pknwij46t/AAXIzGohoFnCQ419YyXD6zI?rlkey=c2544bxgblrcezmycp8qtsfco&dl=0).  
